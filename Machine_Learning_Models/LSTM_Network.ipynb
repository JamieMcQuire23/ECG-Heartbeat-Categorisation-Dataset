{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Network.ipynb",
      "provenance": [],
      "mount_file_id": "1eRk0VAa-tvfcHNlQsXdsHnuyDG1TorgQ",
      "authorship_tag": "ABX9TyPVmdwGLpadbzqlSZCmkvXh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamieMcQuire23/ECG-Heartbeat-Categorisation-Dataset/blob/master/LSTM_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMYSOxApE-VQ",
        "colab_type": "text"
      },
      "source": [
        "# Long Short-Term Memory Network\n",
        "\n",
        "* This notebook will provide a Pytorch implementation of a Recurrent Neural Network for the classification of ECG data.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIB9HyM1FMjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjYuplFHFOdo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2bb3407d-9ff0-41c7-b5b3-2156bc685c22"
      },
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8f10a00eb0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs4XKhXIFQJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mit_train = pd.read_csv(\"/content/drive/My Drive/ECG_HeartBeat_Pytorch/Data/heartbeat/mitbih_train.csv\",header=None)\n",
        "mit_test = pd.read_csv(\"/content/drive/My Drive/ECG_HeartBeat_Pytorch/Data/heartbeat/mitbih_test.csv\",header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTUtbMkIFXp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#convert to the correct form\n",
        "\n",
        "train_vals = mit_train.values\n",
        "X_train = train_vals[:, :-1]\n",
        "Y_train = train_vals[:, -1].astype(int)\n",
        "\n",
        "test_vals = mit_test.values\n",
        "X_test = test_vals[:,:-1]\n",
        "Y_test = test_vals[:,:-1].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs3u0mjyFcAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#create the training and validation set from the training data set\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train,Y_train,test_size=0.2,random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilo7cXkcFpO9",
        "colab_type": "text"
      },
      "source": [
        "# Create the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXlTvvt9Ff14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (1,187)\n",
        "num_classes = 5\n",
        "batch_size = 100\n",
        "learning_rate = 1e-3\n",
        "n_epochs = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTVqGFOsFtKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTM_Model(nn.Module):\n",
        "\n",
        "  def __init__(self,input_dim,hidden_dim,batch_size,output_classes=5,num_layers=3):\n",
        "\n",
        "    super(LSTM_Model,self).__init__()\n",
        "\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.batch_size = batch_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.lstm = nn.LSTM(self.input_dim,self.hidden_dim,self.num_layers)\n",
        "\n",
        "    self.linear = nn.Linear(self.hidden_dim,output_classes)\n",
        "\n",
        "  def forward(self,x):\n",
        "\n",
        "    out, states = self.lstm(x)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rT65tRUI6VG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "00ea0b72-b1ef-4f0b-dffd-b83297417d51"
      },
      "source": [
        "lstm_model = LSTM_Model(input_dim=187,hidden_dim=64,batch_size=100,output_classes=5,num_layers=3)\n",
        "\n",
        "lstm_model.cuda()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_Model(\n",
              "  (lstm): LSTM(187, 64, num_layers=3)\n",
              "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-2LUZSfJfCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mit_train = pd.read_csv(\"/content/drive/My Drive/ECG_HeartBeat_Pytorch/Data/heartbeat/mitbih_train.csv\",header=None)\n",
        "mit_test = pd.read_csv(\"/content/drive/My Drive/ECG_HeartBeat_Pytorch/Data/heartbeat/mitbih_test.csv\",header=None)\n",
        "\n",
        "mit_train, mit_val = train_test_split(mit_train,test_size=0.2,random_state=seed)\n",
        "\n",
        "\n",
        "train_tensor = torch.Tensor(mit_train.values)\n",
        "val_tensor = torch.Tensor(mit_val.values)\n",
        "test_tensor = torch.Tensor(mit_test.values)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_tensor,batch_size=batch_size,\n",
        "                                          shuffle=False,num_workers=2)\n",
        "\n",
        "validationloader = torch.utils.data.DataLoader(val_tensor,batch_size=batch_size,\n",
        "                                               shuffle=False,num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_tensor,batch_size=batch_size,\n",
        "                                          shuffle=False,num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQW_MdGnJio-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def createLossAndOptimizer(net, learning_rate=0.001):\n",
        "    \n",
        "    #Loss function\n",
        "    loss = torch.nn.CrossEntropyLoss()\n",
        "    \n",
        "    #Optimizer\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "    \n",
        "    return(loss, optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx-BM2CVJki8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from torch.autograd import Variable\n",
        "\n",
        "use_cuda = True\n",
        "\n",
        "def trainNet(net, batch_size, n_epochs, learning_rate, trainloader, validationloader):\n",
        "    \n",
        "    #Print all of the hyperparameters of the training iteration:\n",
        "    print(\"===== HYPERPARAMETERS =====\")\n",
        "    print(\"batch_size=\", batch_size)\n",
        "    print(\"epochs=\", n_epochs)\n",
        "    print(\"learning_rate=\", learning_rate)\n",
        "    print(\"=\" * 30)\n",
        "    \n",
        "    n_batches = len(trainloader)\n",
        "    \n",
        "    #Create our loss and optimizer functions\n",
        "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
        "    \n",
        "    #Time for printing\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    #Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        \n",
        "        running_loss = 0.0\n",
        "        print_every = n_batches // 10\n",
        "        start_time = time.time()\n",
        "        total_train_loss = 0\n",
        "        \n",
        "        for i, data in enumerate(trainloader):\n",
        "            \n",
        "            inputs = data[:, :-1]\n",
        "            labels = data[:, -1].long()\n",
        "            sizes = inputs.shape[0]\n",
        "            #inputs form batch_size, features, time_steps\n",
        "            inputs = inputs.reshape(sizes,1,187)\n",
        "\n",
        "            #Wrap them in a Variable object\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            \n",
        "            #Set the parameter gradients to zero\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            #Forward pass, backward pass, optimize\n",
        "            outputs = net(inputs)\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            #Print statistics\n",
        "            running_loss += loss_size.item()\n",
        "            total_train_loss += loss_size.item()\n",
        "            \n",
        "            #Print every 10th batch of an epoch\n",
        "            if (i + 1) % (print_every + 1) == 0:\n",
        "                print(\"Epoch {}, {:d}% \\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                        epoch+1, int(100 * (i+1) / n_batches), running_loss / print_every, time.time() - start_time))\n",
        "                #Reset running loss and time\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            \n",
        "        #At the end of the epoch, do a pass on the validation set\n",
        "        total_val_loss = 0\n",
        "        total = 0\n",
        "        correct = 0\n",
        "        for data in validationloader:\n",
        "\n",
        "            inputs = data[:, :-1]\n",
        "            labels = data[:, -1].long()\n",
        "            sizes = inputs.shape[0]\n",
        "            inputs = inputs.reshape(sizes,1,187)\n",
        "\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              inputs = inputs.cuda()\n",
        "              labels = labels.cuda()\n",
        "            \n",
        "            #Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs), Variable(labels)\n",
        "            \n",
        "            #Forward pass\n",
        "            val_outputs = net(inputs)\n",
        "            val_loss_size = loss(val_outputs, labels)\n",
        "            total_val_loss += val_loss_size.item()\n",
        "\n",
        "            _, predicted = torch.max(val_outputs.data,1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum()\n",
        "            \n",
        "        print(\"Validation loss = {:.2f}\".format(total_val_loss / len(validationloader)))\n",
        "\n",
        "        print(\"Accuracy of the network on the validation data: %d %%\" % (100 * correct/total))\n",
        "        \n",
        "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEPStgcaJqeL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b508555a-4f6f-4cda-b9a4-0cf27d56fb99"
      },
      "source": [
        "trainNet(lstm_model, batch_size, n_epochs, learning_rate, trainloader, validationloader)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== HYPERPARAMETERS =====\n",
            "batch_size= 100\n",
            "epochs= 10\n",
            "learning_rate= 0.001\n",
            "==============================\n",
            "Epoch 1, 10% \t train_loss: 0.14 took: 0.95s\n",
            "Epoch 1, 20% \t train_loss: 0.14 took: 0.84s\n",
            "Epoch 1, 30% \t train_loss: 0.13 took: 0.79s\n",
            "Epoch 1, 40% \t train_loss: 0.15 took: 0.82s\n",
            "Epoch 1, 50% \t train_loss: 0.14 took: 0.92s\n",
            "Epoch 1, 60% \t train_loss: 0.13 took: 0.89s\n",
            "Epoch 1, 70% \t train_loss: 0.14 took: 0.87s\n",
            "Epoch 1, 81% \t train_loss: 0.14 took: 1.01s\n",
            "Epoch 1, 91% \t train_loss: 0.15 took: 0.90s\n",
            "Validation loss = 0.14\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 2, 10% \t train_loss: 0.13 took: 0.87s\n",
            "Epoch 2, 20% \t train_loss: 0.14 took: 0.91s\n",
            "Epoch 2, 30% \t train_loss: 0.12 took: 0.85s\n",
            "Epoch 2, 40% \t train_loss: 0.14 took: 0.84s\n",
            "Epoch 2, 50% \t train_loss: 0.13 took: 0.96s\n",
            "Epoch 2, 60% \t train_loss: 0.13 took: 0.80s\n",
            "Epoch 2, 70% \t train_loss: 0.14 took: 0.89s\n",
            "Epoch 2, 81% \t train_loss: 0.14 took: 0.90s\n",
            "Epoch 2, 91% \t train_loss: 0.15 took: 0.92s\n",
            "Validation loss = 0.14\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 3, 10% \t train_loss: 0.12 took: 0.94s\n",
            "Epoch 3, 20% \t train_loss: 0.13 took: 0.77s\n",
            "Epoch 3, 30% \t train_loss: 0.12 took: 0.87s\n",
            "Epoch 3, 40% \t train_loss: 0.13 took: 0.96s\n",
            "Epoch 3, 50% \t train_loss: 0.13 took: 0.89s\n",
            "Epoch 3, 60% \t train_loss: 0.12 took: 0.87s\n",
            "Epoch 3, 70% \t train_loss: 0.13 took: 0.83s\n",
            "Epoch 3, 81% \t train_loss: 0.13 took: 0.83s\n",
            "Epoch 3, 91% \t train_loss: 0.14 took: 0.92s\n",
            "Validation loss = 0.14\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 4, 10% \t train_loss: 0.12 took: 1.07s\n",
            "Epoch 4, 20% \t train_loss: 0.13 took: 0.86s\n",
            "Epoch 4, 30% \t train_loss: 0.11 took: 0.85s\n",
            "Epoch 4, 40% \t train_loss: 0.13 took: 0.89s\n",
            "Epoch 4, 50% \t train_loss: 0.12 took: 0.94s\n",
            "Epoch 4, 60% \t train_loss: 0.12 took: 0.82s\n",
            "Epoch 4, 70% \t train_loss: 0.13 took: 0.95s\n",
            "Epoch 4, 81% \t train_loss: 0.13 took: 0.90s\n",
            "Epoch 4, 91% \t train_loss: 0.13 took: 0.82s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 5, 10% \t train_loss: 0.11 took: 1.06s\n",
            "Epoch 5, 20% \t train_loss: 0.12 took: 0.92s\n",
            "Epoch 5, 30% \t train_loss: 0.11 took: 0.83s\n",
            "Epoch 5, 40% \t train_loss: 0.12 took: 0.78s\n",
            "Epoch 5, 50% \t train_loss: 0.12 took: 0.91s\n",
            "Epoch 5, 60% \t train_loss: 0.11 took: 0.86s\n",
            "Epoch 5, 70% \t train_loss: 0.12 took: 0.79s\n",
            "Epoch 5, 81% \t train_loss: 0.12 took: 0.85s\n",
            "Epoch 5, 91% \t train_loss: 0.13 took: 0.89s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 6, 10% \t train_loss: 0.11 took: 0.88s\n",
            "Epoch 6, 20% \t train_loss: 0.12 took: 0.83s\n",
            "Epoch 6, 30% \t train_loss: 0.10 took: 0.85s\n",
            "Epoch 6, 40% \t train_loss: 0.12 took: 0.83s\n",
            "Epoch 6, 50% \t train_loss: 0.11 took: 0.84s\n",
            "Epoch 6, 60% \t train_loss: 0.11 took: 0.77s\n",
            "Epoch 6, 70% \t train_loss: 0.12 took: 0.86s\n",
            "Epoch 6, 81% \t train_loss: 0.12 took: 0.84s\n",
            "Epoch 6, 91% \t train_loss: 0.12 took: 0.85s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 7, 10% \t train_loss: 0.11 took: 0.95s\n",
            "Epoch 7, 20% \t train_loss: 0.11 took: 0.86s\n",
            "Epoch 7, 30% \t train_loss: 0.10 took: 0.89s\n",
            "Epoch 7, 40% \t train_loss: 0.12 took: 0.87s\n",
            "Epoch 7, 50% \t train_loss: 0.11 took: 0.78s\n",
            "Epoch 7, 60% \t train_loss: 0.11 took: 0.81s\n",
            "Epoch 7, 70% \t train_loss: 0.11 took: 0.81s\n",
            "Epoch 7, 81% \t train_loss: 0.11 took: 0.88s\n",
            "Epoch 7, 91% \t train_loss: 0.12 took: 0.90s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 8, 10% \t train_loss: 0.10 took: 0.87s\n",
            "Epoch 8, 20% \t train_loss: 0.11 took: 0.78s\n",
            "Epoch 8, 30% \t train_loss: 0.10 took: 0.85s\n",
            "Epoch 8, 40% \t train_loss: 0.11 took: 0.89s\n",
            "Epoch 8, 50% \t train_loss: 0.11 took: 0.82s\n",
            "Epoch 8, 60% \t train_loss: 0.10 took: 0.81s\n",
            "Epoch 8, 70% \t train_loss: 0.11 took: 0.79s\n",
            "Epoch 8, 81% \t train_loss: 0.11 took: 0.80s\n",
            "Epoch 8, 91% \t train_loss: 0.12 took: 0.83s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 9, 10% \t train_loss: 0.10 took: 0.87s\n",
            "Epoch 9, 20% \t train_loss: 0.10 took: 0.86s\n",
            "Epoch 9, 30% \t train_loss: 0.09 took: 0.83s\n",
            "Epoch 9, 40% \t train_loss: 0.11 took: 0.93s\n",
            "Epoch 9, 50% \t train_loss: 0.10 took: 0.92s\n",
            "Epoch 9, 60% \t train_loss: 0.10 took: 1.02s\n",
            "Epoch 9, 70% \t train_loss: 0.11 took: 0.83s\n",
            "Epoch 9, 81% \t train_loss: 0.11 took: 0.83s\n",
            "Epoch 9, 91% \t train_loss: 0.11 took: 0.80s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Epoch 10, 10% \t train_loss: 0.10 took: 0.89s\n",
            "Epoch 10, 20% \t train_loss: 0.10 took: 0.80s\n",
            "Epoch 10, 30% \t train_loss: 0.09 took: 0.80s\n",
            "Epoch 10, 40% \t train_loss: 0.10 took: 1.03s\n",
            "Epoch 10, 50% \t train_loss: 0.10 took: 0.91s\n",
            "Epoch 10, 60% \t train_loss: 0.10 took: 0.84s\n",
            "Epoch 10, 70% \t train_loss: 0.10 took: 0.81s\n",
            "Epoch 10, 81% \t train_loss: 0.10 took: 0.89s\n",
            "Epoch 10, 91% \t train_loss: 0.11 took: 0.78s\n",
            "Validation loss = 0.13\n",
            "Accuracy of the network on the validation data: 96 %\n",
            "Training finished, took 97.12s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd-EdyCNL1P9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7d5dafda-0752-4360-d09b-caa995ae716d"
      },
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for data in testloader:\n",
        "  inputs = data[:, :-1]\n",
        "  labels = data[:, -1].long()\n",
        "  sizes = inputs.shape[0]\n",
        "  inputs = inputs.reshape(sizes,1,187)\n",
        "\n",
        "  if use_cuda and torch.cuda.is_available():\n",
        "    inputs = inputs.cuda()\n",
        "    labels = labels.cuda()\n",
        "\n",
        "  outputs = lstm_model(inputs)\n",
        "  _, predicted = torch.max(outputs.data,1)\n",
        "  total += labels.size(0)\n",
        "  correct += (predicted == labels).sum()\n",
        "\n",
        "print(\"Accuracy of the network on the test data: %d %%\" % (100 * correct/total))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test data: 95 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}